%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}


%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
   \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex

\usepackage{booktabs}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 

% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{amsfonts}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix


\usepackage{booktabs}

%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.


\usepackage{subcaption}

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Unconfused Terminator:\\ Red Neuronal desde cero para MNIST}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Kenneth Obando Rodríguez,~\IEEEmembership{Instituto Tecnológico de Costa Rica}\\
        Alejandro Pacheco Quesada,~\IEEEmembership{Instituto Tecnológico de Costa Rica}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{Inteligencia Artificial, Mayo~2018}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
This paper summarizes the process of implementing a neural network from scratch. It also has the results obtained from
evaluating the network with the train and test sets, using different architecture configurations and different batch sizes. 
The purpose of these results is to evaluate which hyper-parameters gave the best results.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
neural network, gradient descent, softmax, cross-entropy, relu, mnist, machine learning, image classification
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle


\section{Introducción}
\IEEEPARstart{I}{}ndudablemente, poco a poco, el crecimiento y las utilidades que ofrece el área de Machine Learning han aumentado en gran escala. Es 
fascinante ver cómo la tecnología ha adoptado esta área de conocimiento para crear aplicaciones que facilitan o automatizan
muchas tareas. Sin embargo, para muchas personas el funcionamiento
de estas tecnologías es una caja negra y se tiene una idea errónea
de lo que realmente es lo que ``aprenden'' las máquinas y cómo lo hacen.
\par En este proyecto, se pretende romper esa barrera, y se quiere llevar a cabo la implementación de una red neuronal desde cero, de manera que sea posible entender, tanto desde el punto de vista matemático como computacional, cómo funcionan estos modelos de aprendizaje partiendo
de lo más básico, y cómo se da el proceso de aprendizaje mediante
técnicas como gradiente descendiente y \textit{backpropagation}. La red
que se desea implementar va a ser entrenada para clasificar imágenes con
dígitos escritos a mano.
\par La importancia de esto está en, posteriormente, tener una
idea clara de cómo funcionan estos modelos de aprendizaje y poder
implementarlos en otros tipos de problemas. Además, esto da paso
a poder utilizar \textit{frameworks} teniendo el conocimiento necesario para entender lo que está
sucediendo en esa caja negra y saber cómo podrían afectar diferentes cambios al modelo.


\section{Trabajo relacionado}
En este apartado, se citarán algunos trabajos realizados anteriormente en donde se proponen soluciones similares al problema de la investigación.
\par Si bien es cierto que el concepto de red neuronal no es algo que surgió recientemente, no es hasta hace poco tiempo que se han hecho implementaciones reales y prácticas, al punto de obtener tanta popularidad que han llegado a reemplazar algoritmos más antiguos muy usados. Antes del concepto de red neuronal, está detrás el concepto de perceptrón, que podría considerarse como una red neuronal de una única neurona. Este concepto fue mencionado por primera vez en \cite{Perceptron}, creado por Frank Rosenblatt. Debido a las limitaciones que tenía esta propuesta, tiempo después se sugiere la idea de crear capas con múltiples perceptrones. Una de las primeras menciones a esta idea aparece en \cite{percepBook}.
\par Actualmente, se han logrado buenos avances en Machine Learning utilizando diferentes arquitecturas de redes neuronales o variaciones de las mismas. Algunos ejemplos que caben mencionar son las redes de convolución \cite{convnet} y las redes neuronales recurrentes \cite{recnet}. 

\section{Metodología}
Para la resolución del problema y para las pruebas que se mostrarán más adelante, se deben considerar varios conceptos fundamentales: red neuronal, funciones de activación, 
función de pérdida y optimización por \textit{backpropagation}. La metodología consiste en implementar una red neuronal, o perceptrón multicapa, totalmente conectada (\textit{fully-connected}) para la clasificación de imágenes. Para ello, se requiere tener un vector de entrada, que será la capa de entrada. Además, se generan una o varias capas de diferente tamaño con neuronas (o perceptrones), las cuales corresponden a las capas ocultas, y finalmente, una capa de neuronas para la salida, que corresponden a la clasificación que predijo el modelo. Para el aprendizaje, lo que se busca es minimizar la función de pérdida respecto a los pesos $W$ de cada capa, que en esencia, constituyen los parámetros que determinan lo que sabe el modelo. Esta minimización del error se logra ajustando los pesos con \textit{backpropagation}. Con respecto a la clasificación y la activación, se hablará de ello con detalle más adelante. Cabe aclarar que para llevar a cabo este proceso, todas las funciones deben ser diferenciables. 
\par Respecto a los datos, se utilizará el set de datos MNIST. Este set contiene imágenes de $28x28$ píxeles en un solo canal, es decir, son en escala de grises. Este set posee diez clases distintas, que corresponden a los dígitos de las imágenes que se desean clasificar.
\par El lenguaje de programación utilizado fue Python y las operaciones de arreglos se simplificaron al utilizar la biblioteca Numpy.

\subsection{Entrenamiento y testing}
Se desea que la red a implementar sea capaz de reconocer dígitos escritos a mano, que serán pasados en forma de imagen a la red. Para esto, se utilizará el set de datos MNIST. Para el entrenamiento, se utilizarán todas las imágenes destinadas a entrenamiento que ofrece el set de datos, que corresponden a un poco más del 85\% del total de imágenes del set. Para las pruebas, MNIST también tiene un subconjunto de imágenes dedicadas a testing, que corresponden a un poco menos del 15\% del total.

\subsection{Red neuronal}
Constituye el modelo de aprendizaje que se entrenará para posteriormente realizar la clasificación de imágenes. Cada capa que constituye la red, exceptuando la de entrada, posee cierta cantidad de neuronas. Cada una de estas neuronas recibe un conjunto de entradas y para cada entrada hay un peso $W$ asociado. La red que se implementará en el proyecto tiene la siguiente arquitectura:

\begin{itemize}
    \item \textbf{Capa de entrada}: Esta capa corresponde al dato que se quiere clasificar con la red. El tamaño del vector de entrada será justamente el tamaño que tenga el dato. En el caso de esta investigación, al usar MNIST como set de datos, el vector de entrada tiene un tamaño de 784, que resulta del tamaño de cada imagen ($28x28$) visto en una sola  dimensión.
    \item \textbf{Capas ocultas}: Para la red neuronal que se implementará, se van a generar dos capas ocultas o intermedias. El tamaño de cada capa es variable y corresponde a un hyper-parámetro. Por lo tanto, el número de parámetros ($W$), varía según el tamaño de cada capa. 
    \item  \textbf{Capa de salida}: 
    Esta capa corresponde al clasificador de la red neuronal. Se utilizará una neurona por cada clase que tenga el set de datos utilizado. En este caso, al ser 10 clases distintas, la capa de salida tendrá 10 neuronas. Cuando finalmente se activan las neuronas de salida, se elige la que tenga la probabilidad más alta y ésta será la predicción hecha por la red para un dato dado.\\
\end{itemize}

Respecto a las neuronas que conforman las capas, es importante mencionar los siguientes aspectos:
\begin{itemize}
    \item \textbf{Pesos}: Inicialmente, por cada neurona de cada capa, se genera un peso aleatorio utilizando ``Xavier initialization'', que consiste en utilizar una distribución normal estándar para generar los pesos por cada capa. Posteriormente, cada uno de esos pesos es dividido por la raíz cuadrada del tamaño de la capa. Después de generar el primer set de pesos, eventualmente éstos se irán ajustando poco a poco para entrenar el modelo. 
    \item \textbf{Activaciones:} Por cada capa, las neuronas se conforman además de una función de activación que proporciona no linealidad a la red neuronal. Esta función puede ser distinta entre capas, y corresponde a un hyper-parámetro. 
\end{itemize}

\subsection{Forward y funciones de activación}
El \textit{forward pass} corresponde a la acción de clasificación. Se recibe un dato de entrada, en este caso una imagen, y se empieza a evaluar a través de toda la red neuronal. El procedimiento es el siguiente:\\
Para cada neurona $j$ de cada capa, se efectúa una pre-activación que corresponde a una función lineal de la forma \(f(X,W) = X\cdot W\), donde X es el vector de entrada formado por $x_i$ entradas y W es el vector de pesos para esa neurona, donde cada $w_i$ está asociado a una entrada. Entonces, finalmente se tiene una multiplicación de vectores de la forma: 
\begin{equation}\label{eq:linear}
    \sum_{i=1}^{m} x_i w_i
\end{equation}donde m es el tamaño de la entrada. Una vez calculada la pre-activación, ese resultado debe pasar por una función de activación, que da no linealidad a la red. Esto va a dar como resultado al final de la red, la clasificación para la entrada. Para la red implementada, se utilizaron dos funciones de activación distintas:
\begin{itemize}
    \item \textbf{Rectified Linear Units (ReLU)}: esta función de activación se utilizó para las dos capas ocultas de la red, y consiste únicamente en tomar el máximo entre el valor de entrada y 0. La función tiene la siguiente forma: 
    \begin{equation}\label{eq:relu}
        ReLU(x) = 
        \begin{cases}
        x & \text{if } x>0\\
        0 & \text{otherwise}
        \end{cases}
    \end{equation}
    \item \textbf{Softmax}: esta es la función de activación de la capa de salida. Se considera ideal para la última capa ya que esta función da una distribución de probabilidad para cada pre-activación. De esta manera, se estaría realizando la clasificación, y la salida que tenga la probabilidad más alta es la que el modelo considera como la clase perteneciente a la entrada. La función tiene la siguiente forma:
    \begin{equation}\label{eq:softmax}
        \forall \; k_i \in S\text{, }P(Y=K_i|X=x_i) = \frac{e^{S_{k_i}}}{\sum_{j}^{m} e^{S_j}}
    \end{equation}
    donde S corresponde al vector de pre-activaciones de la capa y cada $k_i$ sería una neurona. La sumatoria del denominador, corresponde simplemente a sumar todos los elementos del vector S.
\end{itemize}

\subsection{Función de pérdida: Cross-Entropy}

Parte de la función de pérdida utilizada para medir si el conjunto de pesos de la red cumple con los criterios de optimalidad. En otras palabras, esta función
proporciona el error del modelo de aprendizaje. Este error se ve reflejado en la capa de salida, al comparar la predicción con la clase real del dato. De esta forma, si la clase es incorrecta el error de la red va a aumentar en función de qué tan mal estuvo la predicción. Posteriormente, se deberá minimizar la función de error de manera que el modelo vaya aprendiendo. Para medir la pérdida, se utilizó la función Cross-Entropy. A continuación, se define la fórmula correspondiente:

\begin{equation}\label{eq:crossent}
L_i(S, y_i) = -log(P(Y=y_i|X=x_i))
\end{equation}
\[L_i(S, y_i) = -log(\frac{e^{S_{k_i}}}{\sum_{j}^{m} e^{S_j}})\]
donde el parámetro \(S\) corresponde al vector de activaciones de salida obtenidos al evaluar un dato \(x_i\) en la red neuronal, y el parámetro \(y_i\) corresponde a la etiqueta real del dato. 

Finalmente, la función de \textit{loss} completa, para medir la precisión del modelo con un conjunto de datos de prueba, tiene la siguiente fórmula:
\begin{equation}\label{loss}
L = \frac{1}{N} \sum_{i=1}^{N} Li( S, y_i)
\end{equation}
Donde \(N\) corresponde al total de datos de testing. 

\subsection{Dropout}
Consiste en, aleatoriamente, poner en cero los pesos de cierta cantidad de neuronas de una o ambas capas ocultas. Con esto se pretende que la red aprenda caminos alternativos para clasificar ciertas entradas, y así, evitar \textit{toverfitting}. Para la investigación, se realizarán ejecuciones con y sin \textit{dropout}. El \textit{dropout} se aplicó utilizando una distribución binomial con un $0.2$ de probabilidad.

\subsection{Gradientes y backpropagation}
El \textit{backpropagation} es quizás el proceso más importante de la implementación de la red neuronal. Este consiste en utilizar la gradiente de la función de error para ajustar todos los pesos de manera que minimicen el valor de la función (la pérdida). Esta gradiente se calcula respecto a los pesos de la red, pues es con quienes se desea minimizar el error. Esto puede observarse de la siguiente manera:
\begin{equation}\label{eq:grad}
    \forall \; w \in W, \;  \frac{\partial L}{\partial w}
\end{equation}

Donde $W$ hace referencia al conjunto de todos los pesos de la red. Esto significa que la gradiente surge de todos los pesos y posteriormente se usa realizar el ajuste. Una vez calculada la pendiente de Cross-Entropy con (\ref{eq:grad}), el ajuste para cada peso se realiza de la siguiente manera:

\begin{equation}\label{eq:ajuste}
    W^i = W^{i-1} - \alpha \nabla L
\end{equation}

Para $W^i$, la nueva matriz de pesos, $W^{i-1}$ la matriz de pesos de la iteración anterior y $\alpha$, un hyper-parámetro que establece la magnitud de la distancia entre $W^i$ y \(W^{i-1}\), conocido como \textit{learning rate}.


\section{Experimentos}

\subsection{Conjunto de Datos NMIST}
Para comprobar el funcionamiento de la red neuronal, se utiliza un conjunto de datos llamado NMIST \cite{NMIST}, que consiste en 60000 imágenes de dígitos escritos a mano debidamente etiquetados. Los dígitos se han normalizado y centrado en imágenes de $28 \times 28$ pixeles. Este conjunto de datos se recomiento para el aprendizaje de técnicas de machine learning y de reconocimiento de patrones. El mismo está dividido en un conjunto de entrenamiento de 60000 imágenes y otro conjunto de 10000 imágenes para realizar las pruebas.

Cada prueba se realiza con 30 epochs y batches de 32 imágenes, y se aplica diferentes configuraciones de red neuronal de dos capas y se registra los valores dados por la métrica de error CrossEntropy, y la precisión, tanto de los datos de entrenamiento como de prueba.

Se realiza un entrenamiento con sólo una capa con el fin de comparar su rendimiento respecto a la red con dos capas ocultas.

Además, se prueba la red neuronal utilizando una regularización de Dropout y se registra los valores obtenidos.

Para comprobar el funcionamiento se utilizan 10 números escritos a mano por el equipo de trabajo, estos números se pueden observar en la figura \ref{amano}. Se realiza el proceso de clasificación con la red neuronal ya entrenada.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h0.png}
    \end{subfigure}
     %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h1.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h2.png}
    \end{subfigure}
       \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h3.png}
    \end{subfigure}
    
        \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h4.png}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h5.png}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h6.png}
    \end{subfigure}
            \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h7.png}
    \end{subfigure}
            \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h8.png}
    \end{subfigure}
            \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{h9.png}
    \end{subfigure}
    \label{amano}
    \caption{Imágenes números hechos a mano por los estudiantes}\label{fig:animals}
\end{figure}


\section{Resultados}

\subsection{ Pruebas sin Dropout}
En el entrenamiento principal de la red, la métrica de error CrossEntropy se comporta de la forma esperada, disminuyendo su valor al inicio del entrenamiento considerablemente, luego baja su ritmo de error con varias osilaciones, Se obtiene el menor valor de error al finalizar los 30 epoch con un valor de 0.36 en el conjunto de datos de prueba (ver Figura \ref{crossentropySinDrop}).

Por otra parte, la precisión del modelo se mantiene relativamente estable, aunque mejorando con cada epoch. El proceso se inicia con un 86\% de precisión en el conjunto de prueba y llega a un máximo de 94\%(ver Figura \ref{precisionSinDrop}). 

\begin{figure}[!t]
\centering
\includegraphics[width=3in]{crossentropySinDrop.png}
\caption{Valor de CrossEntropy calculado con NMIST por cada Epoch sin Dropout}
\label{crossentropySinDrop}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=3in]{precisionSinDrop.png}
\caption{Precisión obtenido con NMIST por cada Epoch sin Dropout}
\label{precisionSinDrop}
\end{figure}

\subsection{ Pruebas con Dropout}

Aplicando la regularización, se observa un comportamiento singular alrededor del epoch 8, donde la precisión del modelo mejora sustancialmente después de no lograr valores mayores a 0. En este mismo epoch, se observa un pico en el error de Crossentropy (ver Figura \ref{conDropout}).

La precisión es comparable con la obtenida sin el dropout, aunque más estable. Sospechamos que utilizando una cantidad mucho mayor de epochs, la red neuronal regularizada tendría un mejor rendimiento en comparación a una sin regularizar, gracias a esta misma estabilidad.

\begin{figure}[!t]
\centering
\includegraphics[width=3in]{conDropout.png}
\caption{Valor de CrossEntropy y precisión obtenidos con NMIST por cada Epoch con Dropout}
\label{conDropout}
\end{figure}

\subsection{ Pruebas con Números que no se encuentran en NMIST}

Al utilizar un conjunto de números propios, la red clasifica adecuadamente 4 de ellos. Este débil rendimiento, se debe a que estas imágenes no fueron tratadas con los mismo procedimientos que en NMIST (ver Cuadro 1).

\begin{table}[h]
\centering
\label{num1}
\begin{tabular}{@{}lll@{}}
\toprule
Dígito & Clasificación correcta      \\ \midrule
0      & \checkmark   \\
1      &                             \\
2      &                             \\
3      &                             \\
4      & \checkmark&  \\
5      &                             \\
6      & \checkmark   \\
7      &                             \\
8      &                             \\
9      & \checkmark   \\ \bottomrule
\end{tabular}
\caption{Clasificación de los números escritos por el equipo}
\end{table}



\section{Conclusión}

Esta investigación permite tener una idea general de las características de las redes neuronales y las posibilidades que permite a la hora de modelar la solución a un problema complejo, que por su gran cantidad de variables hace imposible diseñar un código estático \cite{Perceptrons}. 

Una de las principales conclusiones es la potencia computacional de una red neuronal, los modelos matemáticos empleados permiten aprovechar las características de paralelización y vectorización del hardware actual, además, pueden ser fácilmente adaptados a problemas abstractos obteniendo excelentes resultados.

Además, se ha observado como las Redes Neuronales son extremadamente versátiles, permiten incorporar una gran diversidad de parámetros y es por naturaleza modular. Esto lo coloca muy por encima de otras propuestas de aprendizaje como SVM, LASSO y PLS. 

La desventaja principal es que brinda poca información sobre qué variables afectan directamente la estimación, en otras palabras, no son modelos que permitan una interpretación de las variables. 

Por otra parte, gracias a esta investigación, se tiene evidencia empírica de que un batch de mayor tamaño permite un aprendizaje con menor oscilación y por ende, más estable, aunque el proceso se vuelve más lento que al realizarlo por cada imagen independiente.


\section{Trabajo a futuro}

Es una tarea pendiente implementar una red neuronal utilizando la librería CUDA, para utilizar los beneficios de un procesador gráfico GPU. Además, es una tarea pendiente investigar como variables multicorrelacionadas afectan la estimación de una red neuronal.

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\bibliographystyle{IEEEtran}

\begin{thebibliography}{5}

\bibitem{NMIST}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86, 2278–2324.

\bibitem{Dieleman}
Dieleman S., Theano tutorial, (2015), GitHub repository, \url{https://github.com/benanne/theano-tutorial}

\bibitem{James}
James, G., Wittrn, D., Hastie, T., \& Tibshirani, R. (2013). An introduction to Statistical Learning with applications in R. https://doi.org/10.1007/978-1-4614-7138-7

\bibitem{Rakhlin}
Rakhlin, A. (n.d.). 6.883: Online Methods in Machine Learning. Retrieved from http://www.mit.edu/~rakhlin/6.883/lectures/lecture05.pdf

\bibitem{Perceptron}
Rosenblatt, F. (1958). The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain, Cornell Aeronautical Laboratory, Psychological Review, v65, No. 6.

\bibitem{percepBook}
Minsky M. \& Papert S. (1968). Perceptrons. An Introduction to Computational Geometry. American Association for the Advancement of Science, v165, Issue 3895.

\bibitem{Perceptrons}
Perceptrons - the most basic form of a neural network · Applied Go. (n.d.). Retrieved April 8, 2018, from https://appliedgo.net/perceptron/

\bibitem{convnet}
LeCun, Y. (1998). Object Recognition with Gradient-Based Learning. AT\&T Shannon Lab, USA.
 
\bibitem{recnet}
Medsker L.R. \& Jain L.C. (2001). Recurrent Neural Networks: Design and Applications. CRC Press, USA.


\end{thebibliography}

\section*{Anexos}


\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{1}
    \end{subfigure}
     %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{5}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{7.png}
    \end{subfigure}
       \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{9.png}
    \end{subfigure}
    
        \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{11.png}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{13.png}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{15.png}
    \end{subfigure}
            \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{17.png}
    \end{subfigure}
            \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{19.png}
    \end{subfigure}
            \begin{subfigure}[b]{0.2\textwidth}
        \includegraphics[width=\textwidth]{21.png}
    \end{subfigure}
    
    \caption{Imágenes de los pesos para la red entrenada NMIST}\label{fig:animals}
\end{figure}


\end{document}


