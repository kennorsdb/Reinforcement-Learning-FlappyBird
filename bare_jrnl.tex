
\documentclass[journal]{IEEEtran}
    \usepackage[spanish]{babel}
    \selectlanguage{spanish}
    \usepackage[utf8]{inputenc}
    \usepackage{hyperref}


    % *** GRAPHICS RELATED PACKAGES ***
    %
    \ifCLASSINFOpdf
    \usepackage[pdftex]{graphicx}
    \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
    \else

    \fi

    \usepackage{booktabs}
    \usepackage{tikz}
    \def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 

    % *** MATH PACKAGES ***
    %
    \usepackage{amsmath}
    \usepackage{amsfonts}
    \interdisplaylinepenalty=2500

    \usepackage{array}
    \usepackage{fixltx2e}
    \usepackage{stfloats}
    \usepackage{booktabs}
    \usepackage{subcaption}

    % *** PDF, URL AND HYPERLINK PACKAGES ***
    %
    \usepackage{url}

    % correct bad hyphenation here
    \hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

    \title{Reinforcement Learning:\\ FlappyBird}

    \author{Kenneth Obando Rodríguez,~\IEEEmembership{Instituto Tecnológico de Costa Rica}\\
                Alejandro Pacheco Quesada,~\IEEEmembership{Instituto Tecnológico de Costa Rica}}

        % The paper headers
    \markboth{Inteligencia Artificial, Mayo~2018}%
        {Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

        % make the title area
    \maketitle

    
% :::::::::::::::::::::::
%     ABSTRACT
% :::::::::::::::::::::::
\begin{abstract}

\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
neural network, gradient descent, softmax, cross-entropy, relu, mnist, machine learning, image classification
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle


\section{Introducción}
\IEEEPARstart{E}{xisten} problemas computacionales que requieren que un programa realice una acción ante un estado determinado, con la agravante que estos estados pueden tener muchas variables diferentes que lo convierten en una tarea prácticamente imposible para una aproximación estática de la solución. Ante estos problemas, surge toda una rama del campo de la Inteligencia Artificial que se llama Aprendizaje Por Reforzamiento \emph{(``Reinforcement Learning'')}, que consiste, en términos generales, en entrenar un algoritmo utilizando premios \emph{(``reward''))} positivos o negativos, según sea el resultado de la acción tomada en un estado dado.

Esta investigación tiene como objetivo implementar un algoritmo de \emph{Reinforcement Learning} conocido como ``Policy Gradient'' para entrenar un modelo computacional para que juegue con éxito ``FlappyBird'', para ello se utilizan herramientas como PyTorch, 
 

\section{Trabajo relacionado}
Un dato interesante es que el famoso visionario Turing (1948,1950) propuso una aproximación del aprendizaje por reforzamiento aunque no estaba totalmente convencido de su efectividad: \emph{``... el uso de castigos y premios puede, en el mejor de los casos, ser parte de un proceso de enseñanza.''} \cite{Turing1948,Turing1950}. Se sospecha que la primera investigación exitosa en este campo es la de Arthur Samuel, el cual contiene una buena parte de las ideas modernas en parendizaje por reforzamiento, incluyendo la aproximación utilizando una función \cite{Rusell2010}.

Desde principios de la década de los 90 se realizaron aportes en el campo del aprendizaje por reforzamiento utilizando \emph{``Policy Gradient''} inicialmente gracias a Ronald Williams que desarrolló esta familia de algoritmos. Trabajos posteriores hicieron grandes aportes, aunque fue con Papavassiliou y Russel que se describe un nuevo tipo de reforzamiento que converge con cualquier tipo de aproximador de función \cite{Papavassiliou1999}. A partir de estos estudios, se han hecho bastantes aproximaciones, y se ha llevado a una rápida y amplia implementación gracias a herramientas como PyTorch, TensorFlow y hardware como las GPU mediante librerías como CUDA.

Una buena síntesis sobre los métodos que existen actualmente en Policy Gradient se encuentra en \cite{Peters2010}.

\section{Metodología}


\subsection{Entrenamiento y testing}


\subsection{Red neuronal}


\bibliographystyle{IEEEtran}
\bibliography{library}


\section*{Anexos}

    


\end{document}


